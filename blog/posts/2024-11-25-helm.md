---
title_pl: "Kubernetes od zera #2 ‚Äì Helm i pierwszy chart"
title_en: "Kubernetes from scratch #2 ‚Äì Helm and first chart"
date: 2025-11-25
description_pl: Drugi wpis z serii o Kubernetesie ‚Äì dodanie Helm charts do prostego klastra z poprzedniego artyku≈Çu.
description_en: Second post in the Kubernetes series ‚Äì adding Helm charts to the simple cluster from the previous article.
---

## PL

## 1. Wstƒôp

W tym wpisie rozbudowujemy poprzedni przyk≈Çad prostego klastra Kubernetes, 
dodajƒÖc do niego Helm charts. Najpierw wprowadzam kilka zmian w ≈õrodowisku, 
potem przechodzƒô do minimalnego przyk≈Çadu pracy z Helmem, pokazujƒÖc, 
jak wyglƒÖda podstawowa struktura chartu i jak wykonaƒá pierwsze wdro≈ºenie.
Ca≈Ço≈õƒá ma na celu zademonstrowanie, ≈ºe Helm mo≈ºe byƒá u≈ºywany w spos√≥b 
bardzo prosty, a jednocze≈õnie zapewnia solidne fundamenty pod bardziej 
z≈Ço≈ºone scenariusze.

## 2. Czym jest Helm

Helm to mened≈ºer pakiet√≥w dla Kubernetes, kt√≥rego zadaniem jest
uproszczenie procesu wdra≈ºania i zarzƒÖdzania aplikacjami.
Kubernetes wymaga czƒôsto wielu manifest√≥w YAML opisujƒÖcych
Deployment, Service, ConfigMapy, role, ingressy i inne zasoby.
Helm pozwala zebraƒá je w jednƒÖ, sp√≥jnƒÖ strukturƒô, kt√≥rƒÖ mo≈ºna 
≈Çatwo zainstalowaƒá, zaktualizowaƒá lub usunƒÖƒá za pomocƒÖ pojedynczych komend.
Helm dzia≈Ça jak warstwa nad Kubernetesem ‚Äî generuje manifesty,
a nastƒôpnie stosuje je do klastra.
NajwiƒôkszƒÖ korzy≈õciƒÖ jest mo≈ºliwo≈õƒá parametryzacji i ponownego 
wykorzystania tych samych definicji w r√≥≈ºnych ≈õrodowiskach.

### 2.1 Czym sƒÖ Helm Charts

Helm charts to paczki opisujƒÖce aplikacjƒô lub jej fragment w Kubernetesie. Mo≈ºna my≈õleƒá o nich jak o ‚Äûprojekcie‚Äù, w kt√≥rym zorganizowane sƒÖ wszystkie pliki potrzebne do zainstalowania danego komponentu.

Typowy chart sk≈Çada siƒô z czterech g≈Ç√≥wnych element√≥w:

- **Chart** - Zawiera podstawowe metadane chartu: nazwƒô, 
wersjƒô, opis, wersjƒô API Helma.
- **Values** - Plik z warto≈õciami konfiguracyjnymi. 
Chart mo≈ºe ich u≈ºywaƒá w szablonach, 
a u≈ºytkownik mo≈ºe je nadpisywaƒá podczas instalacji.
- katalog **templates/** - Najwa≈ºniejszy katalog chartu. 
Zawiera szablony manifest√≥w Kubernetes, 
kt√≥re Helm przetwarza do finalnego YAML-a.
MogƒÖ to byƒá Deployment, Service, ConfigMap, Ingress itd.
- katalog **charts/** - Katalog na zale≈ºno≈õci, czyli inne charty
wykorzystywane przez ten chart. W prostych projektach pozostaje pusty.

Chart jest wiƒôc uporzƒÖdkowanym zbiorem plik√≥w, 
kt√≥ry pozwala wdra≈ºaƒá aplikacjƒô w powtarzalny i przewidywalny spos√≥b. 
Dziƒôki temu Helm u≈Çatwia pracƒô zar√≥wno w ma≈Çych eksperymentach,
jak i w du≈ºych ≈õrodowiskach produkcyjnych.

## 3. Implementacja

> Ca≈Çy kod ≈∫r√≥d≈Çowy z serii wpis√≥w o Kubernetesie znajduje siƒô w repozytorium na GitHubie pod linkiem poni≈ºej.
> Ka≈ºdy wpis ma sw√≥j osobny branch.
> https://github.com/mpiotro4/k8s_demo/tree/blog/2024-11-25-helm


### 3.1 Pare zmian zanim zaczniemy

Na wstƒôpie parƒô zmian w por√≥wnaniu do ostatniego wpisu.
Po pierwsze nasze proste API sta≈Ço siƒô mniej proste, 
wy≈õwietla parƒô dodatkowych informacji:

```
mpio@Marcins-MacBook-Air ~ % curl localhost:8080 | jq
{
"hostname": "Marcins-MacBook-Air.local",
"namespace": null,
"node_name": null,
"pod_ip": null,
"status": "ok"
}
```

Ponadto przerzuci≈Çem siƒô z klastra zapewnianego przez Rancher na Kind.
Dzia≈Ça to nastƒôpujƒÖco:

```
mpio@Marcins-MacBook-Air ~ % kind create cluster
Creating cluster "kind" ...
‚úì Ensuring node image (kindest/node:v1.34.0) üñº
‚úì Preparing nodes üì¶
‚úì Writing configuration üìú
‚úì Starting control-plane üïπÔ∏è
‚úì Installing CNI üîå
‚úì Installing StorageClass üíæ
Set kubectl context to "kind-kind"
You can now use your cluster with:
kubectl cluster-info --context kind-kind
To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
mpio@Marcins-MacBook-Air ~ % kubectl config get-contexts
CURRENT   NAME        CLUSTER     AUTHINFO    NAMESPACE
*    kind-kind   kind-kind   kind-kind   
```

Z racji ≈ºe u≈ºywamy Kind, konieczna by≈Ça r√≥wnie≈º zmiana typu service z 
LoadBalancer na NodePort. W Rancher Desktop typ LoadBalancer dzia≈Ça, 
poniewa≈º Rancher dostarcza lokalnƒÖ implementacjƒô load balancera i 
potrafi przydzieliƒá zewnƒôtrzny adres IP. Kind takiego mechanizmu 
nie posiada ‚Äì to czysty klaster uruchamiany w kontenerach Dockera,
bez komponentu odpowiadajƒÖcego za realizacjƒô us≈Çug LoadBalancer. 
Dlatego service tego typu nigdy nie dostanie adresu IP i 
pozostaje w stanie ‚Äûpending‚Äù.

Najprostsze rozwiƒÖzanie to u≈ºycie `kubectl port-forward`, 
kt√≥re tworzy tunel z lokalnego portu do portu service 
w klastrze. kubectl zestawia po≈ÇƒÖczenie z API serverem i 
przekazuje ca≈Çy ruch z twojej maszyny do wskazanego service:

```
mpio@Marcins-MacBook-Air ~ % kubectl port-forward service/demo-api 8080:8080
Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080
```
```
mpio@Marcins-MacBook-Air ~ % curl localhost:8080 | jq
{
"hostname": "demo-api-7df9444d9c-f2w47",
"namespace": "default",
"node_name": "kind-control-plane",
"pod_ip": "10.244.0.5",
"status": "ok"
}
```

Tym razem widaƒá jak na d≈Çoni, ≈ºe nasza aplikacja dzia≈Ça wewnƒÖtrz klastra.

### 3.2 Minimalny przyk≈Çad

Jedziemy z Helmem. Najpierw trzeba go oczywi≈õcie zainstalowaƒá, ale to ju≈º pominƒô.
Aby zaczƒÖƒá, mo≈ºna wykorzystaƒá nastƒôpujƒÖcƒÖ komendƒô:

```
mpio@Marcins-MacBook-Air ~ % helm create simple-chart
Creating simple-chart
```

Helm wygenerowa≈Ç pe≈Çny ‚Äûstarter chart‚Äù ‚Äì kompletny zestaw plik√≥w i katalog√≥w,
kt√≥ry ma pokazaƒá, jak zbudowany jest typowy chart.
Wygenerowana zosta≈Ça ca≈Ça struktura: 
`Chart.yaml`, `values.yaml` z du≈ºƒÖ liczbƒÖ przyk≈Çadowych parametr√≥w,
a w katalogu `templates/` wiele zasob√≥w takich jak Deployment, Service, 
Ingress, HPA, ServiceAccount.

To wszystko jest przydatne przy bardziej rozbudowanych projektach, 
ale w naszym przypadku stanowi wy≈ÇƒÖcznie szum. 
Chcemy mieƒá mo≈ºliwie prosty chart pokazujƒÖcy wy≈ÇƒÖcznie Deployment i Service.
Dlatego ca≈Ço≈õƒá porzƒÖdkujemy i zostawiamy tylko minimalny zestaw plik√≥w:

```
simple-chart/
‚îú‚îÄ‚îÄ Chart.yaml
‚îú‚îÄ‚îÄ values.yaml
‚îî‚îÄ‚îÄ templates/
‚îú‚îÄ‚îÄ deployment.yaml
‚îî‚îÄ‚îÄ service.yaml
```

Plik `Chart.yaml` zawiera podstawowe informacje takie jak nazwa czy wersja.
Plik `values.yaml` z kolei mo≈ºe zawieraƒá warto≈õci konfiguracyjne naszego klastra, lecz na ten moment pozostanie pusty.  
Sam Helm zawsze udostƒôpnia obiekt `.Values`, natomiast plik `values.yaml` staje siƒô istotny dopiero w momencie, 
gdy w szablonach zaczynamy siƒô do tych warto≈õci odwo≈Çywaƒá.  
Pliki `deployment.yaml` oraz `service.yaml` pozostajƒÖ bez zmian.

Mamy wszystko, co potrzebne, aby zrobiƒá pierwsze wdro≈ºenie k8s z Helm charts.
W tym celu wykorzystamy komendƒô `helm install`. Helm zainstaluje chart jako tzw. release, czyli instancjƒô charta o konkretnej nazwie w klastrze.

```
mpio@Marcins-MacBook-Air DemoApi % helm install my-release-name ./demo-chart
NAME: my-release-name
LAST DEPLOYED: Tue Nov 25 21:01:00 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
DESCRIPTION: Install complete
TEST SUITE: None
````

Nie bƒôdƒô ju≈º tego pokazywa≈Ç, ale efekt ko≈Ñcowy jest dok≈Çadnie taki sam,
jak wcze≈õniej ‚Äì czyli nasze proste API zosta≈Ço zdeployowane wewnƒÖtrz klastra
k8s. MajƒÖc za sobƒÖ ten minimalny przyk≈Çad, mo≈ºemy przej≈õƒá do kolejnego
kroku, czyli dodaƒá pierwsze warto≈õci konfiguracyjne do naszego charta.

### 3.3 Trochƒô mniej minimalny przyk≈Çad

Na wstƒôpie warto zauwa≈ºyƒá, z czego wynika potrzeba posiadania warto≈õci konfiguracyjnych.
Wystarczy spojrzeƒá m.in. na plik `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-api
  labels:
    app: demo-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: demo-api
  template:
    metadata:
      labels:
        app: demo-api
    spec:
      containers:
      - name: demo-api
        image: kddny/demo_api:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
````

Nazwa `demo-api` pojawia siƒô w wielu miejscach manifest√≥w,
co zwiƒôksza ryzyko pomy≈Çki. Je≈õli w przysz≈Ço≈õci chcia≈Çbym
zmieniƒá nazwƒô aplikacji, musia≈Çbym zaktualizowaƒá jƒÖ rƒôcznie w
kilku plikach, ≈Çatwo przy tym co≈õ przeoczyƒá.

Lepszym podej≈õciem jest przechowywanie takiej warto≈õci w
jednym miejscu i odwo≈Çywanie siƒô do niej w szablonach ‚Äî dok≈Çadnie tak,
jak do parametr√≥w w pliku konfiguracyjnym.

Aby dodaƒá warto≈õci konfiguracyjne do charta, wystarczy umie≈õciƒá wpis w pliku `values.yaml`:

```yaml
appName: demo-api
```

I nastƒôpnie odwo≈Çaƒá siƒô do konkretnej warto≈õci w pliku `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.appName }}
  labels:
    app: {{ .Values.appName }}
spec:
  replicas: 3
  selector:
    matchLabels:
      app: {{ .Values.appName }}
  template:
    metadata:
      labels:
        app: {{ .Values.appName }}
    spec:
      containers:
      - name: {{ .Values.appName }}
        image: kddny/demo_api:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
```

Obiekt `.Values` to mechanizm Helma, kt√≥ry udostƒôpnia zawarto≈õƒá pliku `values.yaml`
w szablonach i pozwala parametryzowaƒá manifesty Kubernetes.

Teraz, gdyby≈õmy chcieli np. zmieniƒá nazwƒô aplikacji, wystarczy zrobiƒá to
w jednym miejscu.

Nowa wersja Helm chart jest gotowa do wdro≈ºenia ‚Äî tym razem u≈ºywam komendy
`helm upgrade`:

```
mpio@Marcins-MacBook-Air DemoApi % helm upgrade my-release-name ./demo-chart 
Release "my-release-name" has been upgraded. Happy Helming!
NAME: my-release-name
LAST DEPLOYED: Sun Nov 30 20:25:27 2025
NAMESPACE: default
STATUS: deployed
REVISION: 2
DESCRIPTION: Upgrade complete
TEST SUITE: None
```

### 4. Podsumowanie

To tyle w tym minimalnym przyk≈Çadzie. Pokazuje on sedno dzia≈Çania Helma:
jest to jedynie warstwa nad Kubernetesem, kt√≥ra generuje i zarzƒÖdza
manifestami w bardziej uporzƒÖdkowany spos√≥b. Sam mechanizm jest prosty,
ale daje ogromne mo≈ºliwo≈õci ‚Äì od templatingu, przez wersjonowanie releas√≥w,
po ≈ÇatwƒÖ aktualizacjƒô i rollback.
W kolejnym wpisie przygotujemy co≈õ bardziej rozbudowanego, aby
lepiej wykorzystaƒá potencja≈Ç Helm charts.

---

## EN

> *This post was translated into English by ChatGPT.*

## 1. Introduction

In this post we extend the previous example of a simple Kubernetes cluster
by adding Helm charts. First, I introduce a few changes to the environment,
then move on to a minimal example of working with Helm, showing what the
basic chart structure looks like and how to perform the first deployment.
The goal is to demonstrate that Helm can be used in a very simple way,
while at the same time providing a solid foundation for more complex scenarios.

## 2. What is Helm

Helm is a package manager for Kubernetes whose purpose is to simplify
the process of deploying and managing applications. Kubernetes typically
requires many YAML manifests describing Deployments, Services, ConfigMaps,
roles, ingresses, and other resources. Helm allows you to group them into
a single, consistent structure that can be easily installed, updated,
or removed using single commands.

Helm acts as a layer on top of Kubernetes ‚Äî it renders manifests and then
applies them to the cluster. The biggest advantage is the ability to
parameterize and reuse the same definitions across different environments.

### 2.1 What are Helm Charts

Helm charts are packages that describe an application or a part of it
in Kubernetes. You can think of a chart as a ‚Äúproject‚Äù that contains all
the files required to install a given component.

A typical chart consists of four main elements:

* **Chart** ‚Äì Contains basic chart metadata such as name, version,
  description, and the Helm API version.
* **Values** ‚Äì A file with configuration values.
  The chart can use them in templates, and users can override them during installation.
* **templates/** directory ‚Äì The most important directory in the chart.
  It contains Kubernetes manifest templates that Helm renders into final YAML files.
  These may include Deployments, Services, ConfigMaps, Ingress resources, etc.
* **charts/** directory ‚Äì A directory for dependencies, that is, other charts
  used by this chart. In simple projects it usually remains empty.

A chart is therefore a well-structured set of files that makes it possible
to deploy applications in a repeatable and predictable way. Thanks to this,
Helm works well both for small experiments and for large production environments.

## 3. Implementation

> The full source code for the Kubernetes series is available in the GitHub repository below.
> Each post has its own dedicated branch.
> [https://github.com/mpiotro4/k8s_demo/tree/blog/2024-11-25-helm](https://github.com/mpiotro4/k8s_demo/tree/blog/2024-11-25-helm)

### 3.1 A few changes before we start

First, a few changes compared to the last post.
Our simple API has become slightly less simple and now shows some additional information:

```
mpio@Marcins-MacBook-Air ~ % curl localhost:8080 | jq
{
"hostname": "Marcins-MacBook-Air.local",
"namespace": null,
"node_name": null,
"pod_ip": null,
"status": "ok"
}
```

I also switched from a cluster provided by Rancher to Kind:

```
mpio@Marcins-MacBook-Air ~ % kind create cluster
Creating cluster "kind" ...
‚úì Ensuring node image (kindest/node:v1.34.0) üñº
‚úì Preparing nodes üì¶
‚úì Writing configuration üìú
‚úì Starting control-plane üïπÔ∏è
‚úì Installing CNI üîå
‚úì Installing StorageClass üíæ
Set kubectl context to "kind-kind"
You can now use your cluster with:
kubectl cluster-info --context kind-kind
To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
mpio@Marcins-MacBook-Air ~ % kubectl config get-contexts
CURRENT   NAME        CLUSTER     AUTHINFO    NAMESPACE
*    kind-kind   kind-kind   kind-kind
```

Because we are using Kind, it was also necessary to change the Service type
from `LoadBalancer` to `NodePort`. In Rancher Desktop, the `LoadBalancer`
type works because Rancher provides a local load balancer implementation
and can assign an external IP address. Kind does not include such a mechanism ‚Äî
it is a plain cluster running in Docker containers, without a component
responsible for handling `LoadBalancer` services. As a result, such a service
never receives an IP address and remains in the ‚Äúpending‚Äù state.

The simplest solution is to use `kubectl port-forward`, which creates a tunnel
from a local port to a Service port in the cluster. kubectl establishes
a connection with the API server and forwards all traffic from your machine
to the selected Service:

```
mpio@Marcins-MacBook-Air ~ % kubectl port-forward service/demo-api 8080:8080
Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080
```

```
mpio@Marcins-MacBook-Air ~ % curl localhost:8080 | jq
{
"hostname": "demo-api-7df9444d9c-f2w47",
"namespace": "default",
"node_name": "kind-control-plane",
"pod_ip": "10.244.0.5",
"status": "ok"
}
```

This time it is clearly visible that our application is running
inside the cluster.

### 3.2 Minimal example

Let‚Äôs move on to Helm. First of all, Helm must be installed,
but I will skip that part here.

To get started, run the following command:

```
mpio@Marcins-MacBook-Air ~ % helm create simple-chart
Creating simple-chart
```

Helm generated a complete ‚Äústarter chart‚Äù ‚Äî a full set of files and directories
that demonstrates how a typical chart is structured. The entire structure
is generated: `Chart.yaml`, `values.yaml` with many example parameters,
and multiple resources inside the `templates/` directory such as Deployment,
Service, Ingress, HPA, and ServiceAccount.

This is useful in more complex projects, but in our case it is only noise.
We want a very simple chart containing only a Deployment and a Service.
So we clean everything up and leave only the minimal set of files:

```
simple-chart/
‚îú‚îÄ‚îÄ Chart.yaml
‚îú‚îÄ‚îÄ values.yaml
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ deployment.yaml
    ‚îî‚îÄ‚îÄ service.yaml
```

The `Chart.yaml` file contains basic information such as the name and version.
The `values.yaml` file can store configuration values for the cluster,
but for now it remains empty.

Helm always provides the `.Values` object, but the `values.yaml` file becomes
important only when templates start referencing these values.

The `deployment.yaml` and `service.yaml` files remain unchanged.

Now we have everything needed to perform the first Helm-based deployment.
We use the `helm install` command. Helm installs the chart as a so-called release,
which is an instance of the chart with a specific name inside the cluster:

```
mpio@Marcins-MacBook-Air DemoApi % helm install my-release-name ./demo-chart
NAME: my-release-name
LAST DEPLOYED: Tue Nov 25 21:01:00 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
DESCRIPTION: Install complete
TEST SUITE: None
```

I will not show it again, but the final result is exactly the same as before ‚Äî
our simple API is deployed inside the Kubernetes cluster.

With this minimal example behind us, we can move on to the next step:
adding the first configuration values to our chart.

### 3.3 Slightly less minimal example

First, it is worth understanding why configuration values are useful.
Just look at the `deployment.yaml` file:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-api
  labels:
    app: demo-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: demo-api
  template:
    metadata:
      labels:
        app: demo-api
    spec:
      containers:
      - name: demo-api
        image: kddny/demo_api:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
```

The name `demo-api` appears in many places in the manifests,
which increases the risk of mistakes. If I wanted to change the application name
in the future, I would have to update it manually in several files,
and it would be easy to miss one.

A better approach is to store such a value in one place and reference it
in templates ‚Äî just like a parameter in a configuration file.

To add configuration values to the chart, simply add an entry in `values.yaml`:

```yaml
appName: demo-api
```

Then reference it in `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.appName }}
  labels:
    app: {{ .Values.appName }}
spec:
  replicas: 3
  selector:
    matchLabels:
      app: {{ .Values.appName }}
  template:
    metadata:
      labels:
        app: {{ .Values.appName }}
    spec:
      containers:
      - name: {{ .Values.appName }}
        image: kddny/demo_api:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
```

The `.Values` object is Helm‚Äôs mechanism for making the contents of `values.yaml`
available inside templates and parameterizing Kubernetes manifests.

Now if we want to change the application name, we only need to modify one file.

The new version of the chart is ready to be deployed ‚Äî this time using
the `helm upgrade` command:

```
mpio@Marcins-MacBook-Air DemoApi % helm upgrade my-release-name ./demo-chart 
Release "my-release-name" has been upgraded. Happy Helming!
NAME: my-release-name
LAST DEPLOYED: Sun Nov 30 20:25:27 2025
NAMESPACE: default
STATUS: deployed
REVISION: 2
DESCRIPTION: Upgrade complete
TEST SUITE: None
```

## 4. Summary

That‚Äôs it for this minimal example. It shows the essence of Helm:
it is simply a layer on top of Kubernetes that generates and manages
manifests in a more structured way.

The mechanism itself is simple, but it enables powerful features ‚Äî
from templating and release versioning to easy upgrades and rollbacks.

In the next post, we will build something more advanced to better
leverage the power of Helm charts.

---